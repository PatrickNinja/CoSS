{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2206f93-517e-440f-9c02-93f1343e8532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "341a2b1d-7fe7-4066-bfe9-64f0795a32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "import importlib\n",
    "import os\n",
    "from os import environ\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from utils.args import get_generate_config\n",
    "from utils.tools import load_vocab, save2file\n",
    "from utils.makeModel import make_model\n",
    "from utils.checkpoint import process_state_dict, load_model\n",
    "from utils.eval import Eval\n",
    "from utils import constants\n",
    "from utils.lang import translate2word\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5ea05c-707a-4aad-b9b6-aba486e4915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.data = kwargs['data']\n",
    "        self.model = kwargs['model']\n",
    "        self.cfg = kwargs['cfg']\n",
    "        self.tokenizer = kwargs['tokenizer']\n",
    "\n",
    "    def _batch(self, st, ed):\n",
    "        try:\n",
    "            output = self.model(source=self.source[st:ed],\n",
    "                                graph=self.graph[st:ed],\n",
    "                                mode='test',\n",
    "                                max_length=self.cfg.target_max_length)\n",
    "            output = output.tolist()\n",
    "            for i in range(len(output)):\n",
    "                output[i] = output[i][1:]\n",
    "                if self.cfg.EOS_index in output[i]:\n",
    "                    end_index = output[i].index(self.cfg.EOS_index)\n",
    "                    output[i] = output[i][:end_index]\n",
    "                print(len(output[i]))\n",
    "\n",
    "        except RuntimeError:\n",
    "            if ed - st == 1:\n",
    "                raise RuntimeError\n",
    "            print('==>Reduce Batch Size')\n",
    "            torch.cuda.empty_cache()\n",
    "            output = []\n",
    "            length = max(int((ed - st) / 4), 1)\n",
    "            while st < ed:\n",
    "                _ed = min(st + length, ed)\n",
    "                output.extend(self._batch(st, _ed))\n",
    "                st = _ed\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self):\n",
    "        outputs = []\n",
    "        self.model.eval()\n",
    "        print('===>Start Generate.')\n",
    "        for batch in tqdm(self.data):\n",
    "            self.source = batch['source_input_ids'].to(self.cfg.device)\n",
    "            self.graph = batch['graph'].to(self.cfg.device)\n",
    "            outs = self._batch(0, self.source.size(0))\n",
    "            dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n",
    "            outputs.extend(dec)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fada242c-ef73-425e-9427-ebf1fcdd081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    beam = 5\n",
    "    source_max_segment = 40\n",
    "    source_max_length = 50\n",
    "    target_max_length = 300\n",
    "    pretrained_model_name_or_path = 'facebook/bart-base'\n",
    "    model_path = \"model/checkpoint5.pkl\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch_size = 16\n",
    "    output_path = \"data\"\n",
    "\n",
    "\n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0214cb7-d6f2-452b-9488-7d09596a86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "test_df = test_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a0d34e-f8be-4f2b-868b-2886034941cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.pretrained_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07cc5fb8-4ebd-4f9b-b5a5-7b943c9a5367",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.PAD_index = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "cfg.BOS_index = tokenizer.convert_tokens_to_ids(tokenizer.bos_token)\n",
    "cfg.EOS_index = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n",
    "cfg.vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e1880d-4984-43f9-9734-0a1c210c17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataset(df, cfg):\n",
    "    D = []\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        node = eval(row['node'])\n",
    "        edge = eval(row['edge'])\n",
    "        docstring = row['docstring']\n",
    "        source_input_ids = []\n",
    "        source_attention_mask = []\n",
    "        target_input_ids = []\n",
    "        target_attention_mask = []\n",
    "        for segment in node[:cfg.source_max_segment]:\n",
    "            segment_tokens = tokenizer(segment, truncation=True, padding=\"max_length\", max_length=cfg.source_max_length)\n",
    "            source_input_ids.append(segment_tokens['input_ids'])\n",
    "            source_attention_mask.append(segment_tokens['attention_mask'])\n",
    "        if len(source_input_ids) < cfg.source_max_segment:\n",
    "            for i in range(len(source_input_ids), cfg.source_max_segment):\n",
    "                segment_tokens = tokenizer(\"\", truncation=True, padding=\"max_length\", max_length=cfg.source_max_length)\n",
    "                source_input_ids.append(segment_tokens['input_ids'])\n",
    "                source_attention_mask.append(segment_tokens['attention_mask'])\n",
    "        graph = [[0] * cfg.source_max_segment for _ in range(cfg.source_max_segment)]\n",
    "\n",
    "        for l, r in edge:\n",
    "            if l < cfg.source_max_segment and r < cfg.source_max_segment:\n",
    "                graph[l][r] = 1\n",
    "\n",
    "        D.append({\n",
    "            \"source_input_ids\": torch.LongTensor(source_input_ids),\n",
    "            \"graph\": torch.LongTensor(graph)\n",
    "        })\n",
    "\n",
    "    dataset = Dataset.from_list(D)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c63170-b874-40e1-90e7-9f5d41767cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e2caed56d64df29a0f0d924e721f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = get_test_dataset(test_df, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75955b8-796f-4ba3-b376-4427b3379709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = load_model(cfg.model_path)\n",
    "model = make_model(cfg)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model = model.to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88e4d83-8cb5-4c31-bd02-55764f77e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_dataset, batch_size=cfg.batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5acb7176-0382-4ab0-aab1-d4de21ef6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = generator(data=test_loader, model=model, tokenizer=tokenizer, cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec80516-3427-456d-b252-a4320782bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>Start Generate.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6c89e734944a2eacec898e4771f2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app/conda/envs/python38/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "outputs = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b2b25a4-bc2e-41a8-bd9e-f3af1e33217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(cfg.output_path):\n",
    "    os.makedirs(cfg.output_path)\n",
    "save_file = os.path.join(cfg.output_path, 'result.txt')\n",
    "save2file(outputs, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2717a-be5c-4c58-8cb6-cf25db9919fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603d10d-b388-4384-8113-d77fd52d864e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5716d32-fbe8-45b5-8529-ec35881845f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9303be-a966-4919-b501-d7ee7b2b796f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717a98c-4b0c-449a-8ad5-8e9ef0564369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b5c19-477e-4502-b50c-28b295a2f907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a2f67-188f-4aca-886f-fc03a79ad21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964d098-1582-4139-b264-de5e25f97fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a443c46-7dcf-47b8-8ddf-cc447e2345d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
